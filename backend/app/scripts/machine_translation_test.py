from typing import Optional, cast
from concurrent.futures import ThreadPoolExecutor
from docling.document_converter import DocumentConverter
from langchain_nebius import ChatNebius
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_text_splitters.sentence_transformers import (
    SentenceTransformersTokenTextSplitter,
)
from langchain_text_splitters.nltk import NLTKTextSplitter
from pydantic import BaseModel, Field
from app.core.config import settings
from langchain_core.messages import SystemMessage, AIMessage, HumanMessage, BaseMessage
from langchain_core.documents import Document
from deepeval.metrics import GEval
from deepeval.test_case import LLMTestCaseParams, LLMTestCase
from deepeval.metrics.g_eval import Rubric
from deepeval import evaluate
from deepeval.evaluate.types import EvaluationResult
from deepeval.models import DeepEvalBaseModel, GPTModel

from app.services.llm.calculate_cost import get_pricing_info

# document parsing
# chunking
# LLM translation + CoT + SO
# LLM as a judge
# feedback loop
# document builder


doc_converter = DocumentConverter()
results = doc_converter.convert(source="app/scripts/eng.md")
results = results.document.export_to_markdown()

text_splitter = NLTKTextSplitter()
text_splitter_2 = SentenceTransformersTokenTextSplitter()

chunks = text_splitter_2.split_text(results)

final_docs: list[Document] = []
for i, chunk in enumerate(chunks):
    final_docs.append(
        Document(
            page_content=chunk,
            metadata={
                "previous_chunk_id": i - 1 if i > 0 else 0,
                "current_chunk_id": i,
                "next_chunk_id": i + 1 if i + 1 < len(chunks) else i,
            },
        )
    )
print(f"Size of chunks {len(chunks)}")

TRANSLATION_PROMPT = """
# Role
You are an expert Context-Aware Translator Agent. Your goal is to translate a specific segment of text (the "Target Chunk") into a specified target language while preserving the semantic flow, tone, and terminology established by the surrounding context.

# Input Data Structure
You will be provided with three specific blocks of text:
1. <previous_context>: The text immediately preceding the target chunk.
2. <target_chunk>: The specific text you must translate.
3. <next_context>: The text immediately following the target chunk.

# Reasoning Process (Chain of Thought)
Before generating the final translation, you must perform the following analysis step-by-step:
1. **Analyze Context**: Look at <previous_context> to identify the subject of the sentence, gender/number of nouns, and specific terminology already used.
2. **Resolve Ambiguities**: If <target_chunk> contains pronouns (e.g., "it", "they"), determine what they refer to based on the previous context.
3. **Check Boundaries**: Look at <next_context>. Ensure your translation ends with a grammatical structure that flows naturally into the start of the next chunk.
4. **Isolate Content**: Confirm exactly where <target_chunk> starts and ends to ensure no content from the context is accidentally translated.

# Strict Instructions
1. **Translate ONLY the <target_chunk>**: Do not translate the previous or next context. They are provided solely for your reference to understand the narrative flow.
2. **Contextual Continuity**:
   - Use <previous_context> to determine correct pronoun references (e.g., identifying if "it" refers to a server or a person) and to maintain consistent terminology.
   - Use <next_context> to ensure your translation leads naturally into the next segment (e.g., avoiding sentence structures that would make the start of the next chunk grammatically awkward).
3. **Formatting**: Preserve all Markdown formatting, HTML tags, or code blocks exactly as they appear in the original text.
4. **Tone**: Match the tone of the source text (e.g., formal, technical, casual).
"""

HUMAN_INPUT_TEMPLATE = """
Target chunk: {target_chunk}
Previous Chunk(optional): {previous_chunk}
Next Chunk(optional): {next_chunk}

Current Language: {current_language}
Target Language: {target_language}
"""

RETRY_PROMPT = """
Retry based strictly on the given feedback:
{feedback}
"""

EVALUATOR_PROMPT = """
# Role
You are a Senior Localization Quality Assurance Specialist and Linguistics Expert. You are tasked with evaluating a specific segment of a translation (the "Target Chunk") generated by an AI agent.

# The Challenge
The translation was performed on a text fragment (chunk) that may not be a complete sentence. The translator was given the surrounding context (<previous_context> and <next_context>) to ensure correct pronoun resolution, grammatical agreement, and terminology consistency.

# Evaluation Criteria
You must score the translation on a scale of 1 to 5 based on the following dimensions:

1.  **Contextual Coherence (Critical)**:
    - Does the translation respect the <previous_context>? (e.g., correct gender/number for pronouns referencing nouns in the previous chunk).
    - Does the translation flow naturally into the <next_context>? (e.g., no abrupt syntactic breaks).
    - **Crucial:** If the chunk splits a sentence, does the translation logically connect the first half (source) to the second half (next context)?

2.  **Semantic Accuracy**:
    - Does the translated text convey the exact meaning of the source <target_chunk>?
    - Are technical terms translated consistently?

3.  **Format Preservation**:
    - Are Markdown tags, code blocks, or special characters preserved exactly?
"""
translation_rubric = [
    Rubric(
        score_range=(0, 2),
        expected_outcome="The translation is missing, irrelevant, or purely hallucinates information not present in the source chunk.",
    ),
    Rubric(
        score_range=(3, 5),
        expected_outcome="The translation conveys general meaning but fails grammatically due to ignoring the 'previous_context' (e.g., wrong gender/number) or breaks the syntax of the 'next_context'.",
    ),
    Rubric(
        score_range=(6, 7),
        expected_outcome="The translation is accurate in isolation but creates a slightly awkward or unnatural transition with the surrounding text chunks.",
    ),
    Rubric(
        score_range=(8, 9),
        expected_outcome="The translation is accurate and grammatically correct within the context, with only very minor stylistic friction.",
    ),
    Rubric(
        score_range=(10, 10),
        expected_outcome="The translation is flawless. It perfectly respects the gender/number from the previous context, flows seamlessly into the next context, and preserves all formatting.",
    ),
]


class TranslatedChunk(BaseModel):
    thought_process: str = Field(
        description="Analysis of the context, pronouns, and sentence flow boundaries."
    )
    translation: str = Field(description="The translation of the target chunk")
    confidence_score: float = Field(
        description="Score from 0.0 to 1.0 on how confident you are in your translation"
    )
    reasoning: str = Field(description="Reasoning for the confidence score value given")


_EVALUATOR_MODEL = "meta-llama/Llama-3.3-70B-Instruct-fast"
_TRANSLATOR_MODEL = "Qwen/Qwen3-235B-A22B-Instruct-2507"

output_price, input_price = get_pricing_info(_EVALUATOR_MODEL)
DEEPEVAL_MODEL = GPTModel(
    model=_EVALUATOR_MODEL,
    api_key=settings.llm_api_key,
    base_url="https://api.studio.nebius.ai/v1/",
    cost_per_input_token=input_price,
    cost_per_output_token=output_price,
)


def evaluate_translation(result: str, messages: list[BaseMessage]) -> EvaluationResult:
    mt_evaluation = GEval(
        name="machine translation evaluation",
        criteria=EVALUATOR_PROMPT,
        evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.INPUT],
        rubric=translation_rubric,
        threshold=0.7,
        model=DEEPEVAL_MODEL,
    )
    test_case = LLMTestCase(input=str(messages), actual_output=result)
    return evaluate(test_cases=[test_case], metrics=[mt_evaluation])


def translation(
    client: BaseChatModel,
    messages: list[BaseMessage],
) -> str:
    client = client.with_structured_output(schema=TranslatedChunk, strict=True)
    final_translation = ""
    while True:
        try:
            results = client.invoke(input=messages)
        except Exception as e:
            raise RuntimeError(f"Something went wrong during invoke: {e}") from e

        print(f"[DEBUG] Results: {str(results)}")

        if results is None:
            print("Translation results cannot be None, Retrying...")
            continue

        translation_results = cast(TranslatedChunk, results)
        print(f"[DEBUG] Starting evaluation on {translation_results.translation}")
        final_translation = translation_results.translation

        eval_results = evaluate_translation(
            result=translation_results.translation, messages=messages
        )
        eval_results = eval_results.test_results[0].metrics_data[0]
        print(f"[DEBUG] Evaluation results: {eval_results.score}")
        if not eval_results.success:
            print(f"[DEBUG] Retrying due to reason: {eval_results.reason}")
            messages.append(AIMessage(content=translation_results.translation))
            messages.append(
                HumanMessage(content=RETRY_PROMPT.format(feedback=eval_results.reason))
            )
        else:
            print(f"[DEBUG] Passed ({eval_results.score})")
            break

    return final_translation


messages_list: list[list[BaseMessage]] = []
client_list: list[BaseChatModel] = []

for _, doc in enumerate(final_docs):
    client = ChatNebius(model=_TRANSLATOR_MODEL, api_key=settings.llm_api_key)

    messages = [
        SystemMessage(content=TRANSLATION_PROMPT),
        HumanMessage(
            content=HUMAN_INPUT_TEMPLATE.format(
                target_chunk=doc.page_content,
                current_language="english",
                target_language="filipino",
                previous_chunk=final_docs[doc.metadata["previous_chunk_id"]]
                if doc.metadata["previous_chunk_id"] != doc.metadata["current_chunk_id"]
                else "",
                next_chunk=final_docs[doc.metadata["next_chunk_id"]]
                if doc.metadata["next_chunk_id"] != doc.metadata["current_chunk_id"]
                else "",
            )
        ),
    ]

    client_list.append(client)
    messages_list.append(messages)

final_translation = ""
with ThreadPoolExecutor(max_workers=20) as executor:
    results = executor.map(translation, client_list, messages_list)

    for result in results:
        final_translation += result

print(final_translation)

with open("filipino.md", mode="w") as file:
    file.write(final_translation)
