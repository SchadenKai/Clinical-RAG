from typing import Optional, cast
from concurrent.futures import ThreadPoolExecutor
from docling.document_converter import DocumentConverter
from langchain_nebius import ChatNebius
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_text_splitters.sentence_transformers import (
    SentenceTransformersTokenTextSplitter,
)
from langchain_text_splitters.nltk import NLTKTextSplitter
from pydantic import BaseModel, Field
from app.core.config import settings
from langchain_core.messages import SystemMessage, AIMessage, HumanMessage, BaseMessage
from langchain_core.documents import Document
from deepeval.metrics import GEval
from deepeval.test_case import LLMTestCaseParams, LLMTestCase
from deepeval.metrics.g_eval import Rubric
from deepeval import evaluate
from deepeval.evaluate.types import EvaluationResult


# document parsing
# chunking
# LLM translation + CoT + SO
# LLM as a judge
# feedback loop
# document builder


doc_converter = DocumentConverter()
results = doc_converter.convert(source="app/scripts/eng.md")
results = results.document.export_to_markdown()

text_splitter = NLTKTextSplitter()
text_splitter_2 = SentenceTransformersTokenTextSplitter()

chunks = text_splitter_2.split_text(results)

final_docs: list[Document] = []
for i, chunk in enumerate(chunks):
    final_docs.append(
        Document(
            page_content=chunk,
            metadata={
                "previous_chunk_id": i - 1 if i > 0 else 0,
                "current_chunk_id": i,
                "next_chunk_id": i + 1 if i + 1 < len(chunks) else i,
            },
        )
    )
print(f"Size of chunks {len(chunks)}")

TRANSLATION_PROMPT = """
# Role
You are an expert Context-Aware Translator Agent. Your goal is to translate a specific segment of text (the "Target Chunk") into a specified target language while preserving the semantic flow, tone, and terminology established by the surrounding context.

# Input Data Structure
You will be provided with three specific blocks of text:
1. <previous_context>: The text immediately preceding the target chunk.
2. <target_chunk>: The specific text you must translate.
3. <next_context>: The text immediately following the target chunk.

# Strict Instructions
1. **Translate ONLY the <target_chunk>**: Do not translate the previous or next context. They are provided solely for your reference to understand the narrative flow.
2. **Contextual Continuity**:
   - Use <previous_context> to determine correct pronoun references (e.g., identifying if "it" refers to a server or a person) and to maintain consistent terminology.
   - Use <next_context> to ensure your translation leads naturally into the next segment (e.g., avoiding sentence structures that would make the start of the next chunk grammatically awkward).
3. **Formatting**: Preserve all Markdown formatting, HTML tags, or code blocks exactly as they appear in the original text.
4. **Tone**: Match the tone of the source text (e.g., formal, technical, casual).
"""

HUMAN_INPUT_TEMPLATE = """
Target chunk: {target_chunk}
Previous Chunk(optional): {previous_chunk}
Next Chunk(optional): {next_chunk}

Current Language: {current_language}
Target Language: {target_language}
"""

EVALUATOR_PROMPT = """
# Role
You are a Senior Localization Quality Assurance Specialist and Linguistics Expert. You are tasked with evaluating a specific segment of a translation (the "Target Chunk") generated by an AI agent.

# The Challenge
The translation was performed on a text fragment (chunk) that may not be a complete sentence. The translator was given the surrounding context (<previous_context> and <next_context>) to ensure correct pronoun resolution, grammatical agreement, and terminology consistency.

# Evaluation Criteria
You must score the translation on a scale of 1 to 5 based on the following dimensions:

1.  **Contextual Coherence (Critical)**:
    - Does the translation respect the <previous_context>? (e.g., correct gender/number for pronouns referencing nouns in the previous chunk).
    - Does the translation flow naturally into the <next_context>? (e.g., no abrupt syntactic breaks).
    - **Crucial:** If the chunk splits a sentence, does the translation logically connect the first half (source) to the second half (next context)?

2.  **Semantic Accuracy**:
    - Does the translated text convey the exact meaning of the source <target_chunk>?
    - Are technical terms translated consistently?

3.  **Format Preservation**:
    - Are Markdown tags, code blocks, or special characters preserved exactly?

# Scoring Rubric (1-5)
- **5 (Perfect):** Flawless translation. Grammatically perfectly aligned with previous/next contexts. Terminology is precise.
- **4 (Good):** Meaning is accurate, but minor stylistic friction with the context (e.g., a slightly awkward transition).
- **3 (Acceptable):** Meaning is preserved, but context cues were missed (e.g., used "it" generically instead of the specific gender implied by previous text).
- **2 (Poor):** Significant meaning errors or the translation makes the combined sentence (chunk + next) grammatically incorrect.
- **1 (Fail):** Hallucination, missing translation, or broken formatting.
"""
translation_rubric = [
    Rubric(
        score=1,
        criteria="The translation is missing, irrelevant, or purely hallucinates information not present in the source chunk.",
    ),
    Rubric(
        score=2,
        criteria="The translation conveys general meaning but fails grammatically due to ignoring the 'previous_context' (e.g., wrong gender/number) or breaks the syntax of the 'next_context'.",
    ),
    Rubric(
        score=3,
        criteria="The translation is accurate in isolation but creates a slightly awkward or unnatural transition with the surrounding text chunks.",
    ),
    Rubric(
        score=4,
        criteria="The translation is accurate and grammatically correct within the context, with only very minor stylistic friction.",
    ),
    Rubric(
        score=5,
        criteria="The translation is flawless. It perfectly respects the gender/number from the previous context, flows seamlessly into the next context, and preserves all formatting.",
    ),
]


class TranslatedChunk(BaseModel):
    translation: str = Field(description="The translation of the target chunk")
    confidence_score: float = Field(
        description="Score from 0.0 to 1.0 on how confident you are in your translation"
    )
    reasoning: str = Field(description="Reasoning for the confidence score value given")


final_translation = ""


def evaluate_translation(result: str, messages: list[BaseMessage]) -> EvaluationResult:
    mt_evaluation = GEval(
        name="machine translation evaluation",
        criteria=EVALUATOR_PROMPT,
        evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.INPUT],
        rubric=translation_rubric,
        threshold=4
    )
    test_case = LLMTestCase(input=str(messages), actual_output=result)
    return evaluate(test_cases=[test_case], metrics=[mt_evaluation])


def translation(
    client: BaseChatModel,
    messages: list[BaseMessage],
    is_confident: Optional[bool] = False,
) -> str:
    client = client.with_structured_output(schema=TranslatedChunk, strict=True)
    while not is_confident:
        print(is_confident)
        results = client.invoke(input=messages)
        results = cast(TranslatedChunk, results)
        print(results)
        if results.confidence_score < 0.7:
            print(
                f"[DEBUG] Confidence score too low ({results.confidence_score})"
                f": Retrying... (reason:{results.reasoning})"
            )
            messages.append(AIMessage(content=(results)))
            messages.append(HumanMessage(content="Retry based on the given reasoning"))
            is_confident = False
        else:
            eval_results = evaluate_translation(results.translation, messages)
            eval_results = eval_results.test_results[0].metrics_data[0]
            if not eval_results.success:
                messages.append(AIMessage(content=(results)))
                messages.append(HumanMessage(content=eval_results.reason))
                is_confident = False
            else:
                print(f"[DEBUG] Passed ({results.confidence_score})")
                is_confident = True
    return results.translation


messages_list: list[list[BaseMessage]] = []
client_list: list[BaseChatModel] = []

for _, doc in enumerate(final_docs):
    client = ChatNebius(
        model="meta-llama/Llama-3.3-70B-Instruct-fast", api_key=settings.llm_api_key
    )

    messages = [
        SystemMessage(content=TRANSLATION_PROMPT),
        HumanMessage(
            content=HUMAN_INPUT_TEMPLATE.format(
                target_chunk=doc.page_content,
                current_language="english",
                target_language="filipino",
                previous_chunk=final_docs[doc.metadata["previous_chunk_id"]]
                if doc.metadata["previous_chunk_id"] != doc.metadata["current_chunk_id"]
                else "",
                next_chunk=final_docs[doc.metadata["next_chunk_id"]]
                if doc.metadata["next_chunk_id"] != doc.metadata["current_chunk_id"]
                else "",
            )
        ),
    ]

    client_list.append(client)
    messages_list.append(messages)

final_translation = ""
with ThreadPoolExecutor(max_workers=10) as executor:
    results = executor.map(translation, client_list, messages_list)

    for result in results:
        final_translation += result

print(final_translation)

with open("filipino.md", mode="w") as file:
    file.write(final_translation)
